version: '3'

# This docker-compose is for developer convenience, not for running in production.

services:

  spark-master:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-master
    ports:
      - "8090:8090"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_WEBUI_PORT=8090
      - MAX_EXECUTORS=4
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
    volumes:
      - ./cdr/cdm/jupyter:/cdm_shared_workspace

  spark-worker-1:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_WEBUI_PORT=8081
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
    volumes:
      - ./cdr/cdm/jupyter:/cdm_shared_workspace

  spark-worker-2:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_WEBUI_PORT=8082
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
    volumes:
      - ./cdr/cdm/jupyter:/cdm_shared_workspace

  minio:
    image: minio/minio
    container_name: spark-minio
    ports:
      - "9002:9002"
      # MinIO Console is available at http://localhost:9003
      - "9003:9003"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    healthcheck:
      # reference: https://github.com/rodrigobdz/docker-compose-healthchecks?tab=readme-ov-file#minio-release2023-11-01t18-37-25z-and-older
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9002' || exit 1
      interval: 1s
      timeout: 10s
      retries: 5
    # Note there is no bucket by default
    command: server --address 0.0.0.0:9002 --console-address 0.0.0.0:9003 /data

  minio-create-bucket:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      bash -c "
      mc alias set minio http://minio:9002 minio minio123 &&
      if ! mc ls minio/cdm-lake 2>/dev/null; then
        mc mb minio/cdm-lake && echo 'Bucket cdm-lake created'
      else
        echo 'bucket cdm-lake already exists'
      fi &&
      mc admin user add minio minio-readonly minio123 &&
      mc admin policy create minio cdm-lake-read-only-policy /config/cdm-lake-read-only-policy.json &&
      mc admin policy attach minio cdm-lake-read-only-policy --user=minio-readonly &&
      echo 'CDM Read-only user and policy set'
      "
    volumes:
      - ./config/cdm-lake-read-only-policy.json:/config/cdm-lake-read-only-policy.json

  dev_notebook:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-dev-notebook
    ports:
      - "4041:4041"
    depends_on:
      - spark-master
      - minio-create-bucket
    environment:
      - NOTEBOOK_PORT=4041
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_DRIVER_HOST=spark-dev-notebook
      - MINIO_URL=http://minio:9002
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
      - SPARK_MODE=notebook
      - MAX_EXECUTORS=4
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
      - USAGE_MODE=dev  # Enabling dev mode grants full access to MinIO and additional privileges for services like Hive, such as the ability to create tables as defined in the scripts/setup.sh.
    volumes:
      - ./cdr/cdm/jupyter:/cdm_shared_workspace

  user_notebook:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-user-notebook
    ports:
      - "4042:4042"
    depends_on:
      - spark-master
      - minio-create-bucket
    environment:
      - NOTEBOOK_PORT=4042
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_DRIVER_HOST=spark-user-notebook
      - MINIO_URL=http://minio:9002
      - MINIO_ACCESS_KEY=minio-readonly
      - MINIO_SECRET_KEY=minio123
      - SPARK_MODE=notebook
      - MAX_EXECUTORS=4
      # TODO: create postgres user w/ only write access to the hive tables
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
    volumes:
      - ./cdr/cdm/jupyter/user_shared_workspace:/cdm_shared_workspace/user_shared_workspace

  postgres:
    image: postgres:16.3
    restart: always
    container_name: postgres_spark
    # To avoid incorrect user permissions, manually create the volume directory before running Docker.
    # export UID=$(id -u)
    # export GID=$(id -g)
    # mkdir -p cdr/cdm/jupyter/cdm-postgres
    # reference: https://forums.docker.com/t/systemd-coredump-taking-ownership-of-tmp-db-directory-and-contents-in-rails-app/93609
    user: "${UID}:${GID}"
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
    volumes:
      - ./cdr/cdm/jupyter/cdm-postgres:/var/lib/postgresql/data  # For local development only. In Rancher development, PostgreSQL data shouldn't be stored in a shared mount.