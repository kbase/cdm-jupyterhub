version: '3'

# This docker-compose is for developer convenience, not for running in production.

services:

  yarn-resourcemanager:
    image: ghcr.io/kbase/cdm-prototype-yarn:pr-8
    # Images from the ghcr.io/kbase registry are exclusively available for Linux/AMD64 platforms.
    platform: linux/amd64
    ports:
      - 8088:8088  # web ui
    environment:
      - YARN_MODE=resourcemanager
      - MINIO_URL=http://minio:9002
      - MINIO_ACCESS_KEY=yarnuser
      - MINIO_SECRET_KEY=yarnpass
    networks:
      - cdm-jupyterhub-network

  yarn-nodemanager:
    image: ghcr.io/kbase/cdm-prototype-yarn:pr-8
    platform: linux/amd64
    ports:
      - 8042:8042  # web ui
    environment:
      - YARN_MODE=nodemanager
      - YARN_RESOURCEMANAGER_HOSTNAME=yarn-resourcemanager
      - MINIO_URL=http://minio:9002
      - MINIO_ACCESS_KEY=yarnuser
      - MINIO_SECRET_KEY=yarnpass
    networks:
      - cdm-jupyterhub-network

  spark-master:
    # The latest image from cdm-jupyterhub that includes spark standalone mode
    image: ghcr.io/kbase/cdm-spark-standalone:pr-19
    platform: linux/amd64
    ports:
      - "8090:8090"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_WEBUI_PORT=8090
      - MAX_EXECUTORS=5
      - EXECUTOR_CORES=2
      - MAX_CORES_PER_APPLICATION=10
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
    volumes:
      - ./cdr/cdm/jupyter/cdm_shared_workspace:/cdm_shared_workspace
    networks:
      - cdm-jupyterhub-network

  spark-worker-1:
    # The latest image from cdm-jupyterhub that includes spark standalone mode
    image: ghcr.io/kbase/cdm-spark-standalone:pr-19
    platform: linux/amd64
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=10
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_WEBUI_PORT=8081
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
    volumes:
      - ./cdr/cdm/jupyter/cdm_shared_workspace:/cdm_shared_workspace
    networks:
      - cdm-jupyterhub-network

  spark-worker-2:
    # The latest image from cdm-jupyterhub that includes spark standalone mode
    image: ghcr.io/kbase/cdm-spark-standalone:pr-19
    platform: linux/amd64
    ports:
      - "8082:8082"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=10
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_WEBUI_PORT=8082
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
    volumes:
      - ./cdr/cdm/jupyter/cdm_shared_workspace:/cdm_shared_workspace
    networks:
      - cdm-jupyterhub-network

  minio:
    image: minio/minio
    ports:
      - "9002:9002"
      # MinIO Console is available at http://localhost:9003
      - "9003:9003"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    healthcheck:
      # reference: https://github.com/rodrigobdz/docker-compose-healthchecks?tab=readme-ov-file#minio-release2023-11-01t18-37-25z-and-older
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9002' || exit 1
      interval: 1s
      timeout: 10s
      retries: 5
    # Note there is no bucket by default
    command: server --address 0.0.0.0:9002 --console-address 0.0.0.0:9003 /data
    networks:
      - cdm-jupyterhub-network

  minio-create-bucket:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: /scripts/minio_create_bucket_entrypoint.sh
    volumes:
      - ./config/cdm-read-only-policy.json:/config/cdm-read-only-policy.json
      - ./config/cdm-read-write-policy.json:/config/cdm-read-write-policy.json
      - ./config/yarn-write-policy.json:/config/yarn-write-policy.json
      - ./scripts/minio_create_bucket_entrypoint.sh:/scripts/minio_create_bucket_entrypoint.sh
    networks:
      - cdm-jupyterhub-network

  cdm_jupyterhub:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cdm-jupyterhub
    platform: linux/amd64
    ports:
      - "4043:4043"
    depends_on:
      - minio-create-bucket
    environment:
      - NOTEBOOK_PORT=4043
      - JUPYTER_MODE=jupyterhub
      - YARN_RESOURCE_MANAGER_URL=http://yarn-resourcemanager:8032
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_DRIVER_HOST=cdm-jupyterhub
      - MINIO_URL=http://minio:9002
      - MINIO_ACCESS_KEY=minio-readonly
      - MINIO_SECRET_KEY=minio123
      - MINIO_RW_ACCESS_KEY=minio-readwrite
      - MINIO_RW_SECRET_KEY=minio123
      - S3_YARN_BUCKET=yarn
      - MAX_EXECUTORS=4
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
      - JUPYTERHUB_ADMIN_PASSWORD=testpassword123
      - NETWORK_NAME=cdm-jupyterhub-network
      - JUPYTERHUB_USER_IMAGE=cdm-jupyterhub-cdm_jupyterhub:latest
      # Ensure that the JUPYTERHUB_MOUNT_BASE_DIR directory below is an absolute path and exists on your local machine.
      - JUPYTERHUB_MOUNT_BASE_DIR=/cdr/cdm/jupyter
      - ENVIRONMENT=dev
      - KB_ENV=ci
      - AUTH_FULL_ADMIN_ROLES=CDM_JUPYTERHUB_ADMIN
      - USE_KBASE_AUTHENTICATOR=true
      - USE_KUBE_SPAWNER=false
      - REMOVE_STOPPED_CONTAINER_AND_POD=false
    volumes:
      - ./cdr/cdm/jupyter/cdm_shared_workspace:/cdm_shared_workspace
      - ./cdr/cdm/jupyter/jupyterhub_secrets:/jupyterhub_secrets
      - ./cdr/cdm/jupyter/jupyterhub/users_home:/jupyterhub/users_home
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - cdm-jupyterhub-network

  cdm-mcp-server:
    image: ghcr.io/kbase/cdm-mcp-server:pr-14
    platform: linux/amd64
    ports:
      - "8000:8000"
    environment:
      - MINIO_URL=http://minio:9002
      - MINIO_ACCESS_KEY=minio-readonly
      - MINIO_SECRET_KEY=minio123
      - SPARK_MASTER_URL=spark://spark-master:7077
      - KBASE_AUTH_URL=https://ci.kbase.us/services/auth/
      - KBASE_ADMIN_ROLES=CDM_JUPYTERHUB_ADMIN
      - SPARK_DRIVER_HOST=cdm-mcp-server
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
      - POSTGRES_URL=postgres:5432
      - SPARK_POOL=highPriority
      - EXECUTOR_CORES=10
    volumes:
      - ./cdr/cdm/jupyter/cdm_shared_workspace:/cdm_shared_workspace
    networks:
      - cdm-jupyterhub-network

  postgres:
    image: postgres:16.3
    # To avoid incorrect user permissions, manually create the volume directory before running Docker.
    # export UID=$(id -u)
    # export GID=$(id -g)
    # mkdir -p cdr/cdm/jupyter/cdm-postgres
    # reference: https://forums.docker.com/t/systemd-coredump-taking-ownership-of-tmp-db-directory-and-contents-in-rails-app/93609
    user: "${UID}:${GID}"
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hivepassword
      - POSTGRES_DB=hive
    volumes:
      - ./cdr/cdm/jupyter/cdm-postgres:/var/lib/postgresql/data  # For local development only. In Rancher development, PostgreSQL data shouldn't be stored in a shared mount.
    networks:
      - cdm-jupyterhub-network

networks:
  # Created by `docker network create cdm-jupyterhub-network`
  cdm-jupyterhub-network:
    external: true
